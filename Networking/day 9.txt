Stateful Inspection firewalls

Stateful inspection firewalls are integral in active network connection monitoring. By tracking these connections, they analyze the context of incoming and outgoing traffic, ensuring only safe data packets traverse the network. Located at Layers 3 and 4 of the Open Systems Interconnection (OSI) model, their primary function is to filter traffic based on its state and context. This method is more thorough than mere packet-level protection because it understands the broader context of data exchanges.
The underlying technology of a stateful firewall is its ability to perform packet inspection. It scrutinizes the contents of each data packet to determine if it matches the attributes of previously recognized safe connections.

Layer 3 vs. Layer 7 Firewall

A Layer 3 firewall functions at the network layer of the Open Systems Interconnection (OSI) model. It primarily focuses on filtering traffic based on parameters like IP addresses, port numbers, and specific protocols, making its approach broad and akin to routers' operations. This type of firewall offers efficient and wide-ranging coverage, providing protection by allowing or denying packets based on their source and destination details.
Conversely, a Layer 7 firewall operates at the application layer of the OSI model. Its main advantage lies in its ability to deeply inspect the content within data packets. By analyzing the specific contents, it can discern between benign and malicious application-specific traffic, effectively guarding against threats like SQL injections or other application-layer attacks.

How to Choose the Right Firewall for a Business Network

Selecting an appropriate firewall for a business network requires a clear understanding of the network architecture, protected assets, and specific organizational needs.
Start by defining the technical objectives of the firewall. Determine if the network requires a comprehensive solution or if a more straightforward firewall suffices. It's crucial to consider the type of network, importance of assets, budget, and expected traffic, for starters. Assess how firewall products integrate into existing infrastructure. Finally, be sure to consider compliance requirements and relevant data protection laws.

What are the 3 types of firewalls in cyber security?
,
There are many examples of firewall types. While the classification of firewalls can vary based on criteria and context, three commonly mentioned types are:
Packet-Filtering Firewalls: Operate at the network level and use rules to allow or block data based on source and destination IP addresses, ports, and protocols.
Stateful Inspection Firewalls: Also known as dynamic packet filtering firewalls, they not only examine packets but also keep track of active sessions and determine if the packet is part of an established connection.
Proxy Firewalls: Operate at the application layer, acting as intermediaries between users and the services they wish to access, filtering traffic by ensuring that incoming data is coming from a legitimate source.

https://www.appviewx.com/wp-content/uploads/2021/01/what-is-a-load-balancer.png
 
1: What is a Load balancer?
	2: Understanding functions of Load Balancer
	3: How do load balancers work?
	4: Types of Load Balancers – Based on Function
	5: Types of Load Balancers – Based on Configuration
	6: L4, L7, and GSLB load balancers, explained
	7: Why is load balancing necessary?
	8: Load Balancing Methods
		-> Industry Standard Algorithms
		-> Other Specific Algorithm
	9.Benefits of Load Balancers
		-> Benefits to the website/application
		-> Benefits to the organization  

A load balancer is a solution that acts as a traffic proxy and distributes network or application traffic across endpoints on a number of servers. 
Load balancers are used to distribute capacity during peak traffic times, and to increase reliability of applications. 
They improve the overall performance of applications by decreasing the burden on individual services or clouds, and distribute the demand across different compute surfaces to help maintain application and network sessions. 
Modern applications must process millions of sessions simultaneously and return the correct text, videos, images, and other data to each user in a fast and reliable manner. 
To handle such high volumes of traffic, most applications have many resource servers with duplicate data among them.

Understanding the functions of load balancers

In general, a Load Balancer acts as a ‘traffic controller’ for your server and directs the requests to an available one, capable of fulfilling the request efficiently. This ensures that requests are responded to fast and no server is over-stressed to degrade the performance.
In an organization’s attempt to meet the application demands, Load Balancer assists in deciding which server can efficiently handle the requests. This creates a better user experience.
By helping servers move data efficiently, information flow between the server and endpoint device is also managed by the load balancer. It also assesses the request-handling health of the server, and if necessary, Load Balancer removes the unhealthy server until it is restored.
As the servers can also be physical or virtual, a load balancer can also be a hardware appliance or a software-based virtual one. When a server goes down, the requests are directed to the remaining servers and when a new server gets added, the requests automatically start getting transferred to it.

HOW DO LOAD BALANCERS WORK 
	-> https://www.appviewx.com/wp-content/uploads/2021/01/how-do-load-balancers-work.png
	-> A load balancer may be:
		-> A physical device, a virtualized instance running on specialized hardware, or a software process.
		-> Application delivery controllers, which are incorporated into ADCs, are designed to improve the performance and security of applications, no matter where they are hosted.
		-> Able to handle many possible algorithms for balancing the load on your server farm, including round-robin, server response time, and the least connection method.
		-> Load balancers detect the health of backend resources and only send traffic to servers that are not able to satisfy requests.
		-> Load balancers should ultimately deliver the performance and security necessary for sustaining complex IT environments and their intricate workflows.

Types of Load Balancers – Based on Functions
Several load balancing techniques are there for addressing the specific network issues:

a.) Network Load Balancer / Layer 4 (L4) Load Balancer:
Based on the network variables like IP address and destination ports, Network Load balancing is the distribution of traffic at the transport level through the routing decisions. Such load balancing is TCP i.e. level 4, and does not consider any parameter at the application level like the type of content, cookie data, headers, locations, application behavior etc. Performing network addressing translations without inspecting the content of discrete packets, Network Load Balancing cares only about the network layer information and directs the traffic on this basis only.

b.) Application Load Balancer / Layer 7 (L7) Load Balancer:
-> Ranking highest in the OSI model, Layer 7 load balancer distributes the requests based on multiple parameters at the application level.
-> A much wider range of data is evaluated by the L7 load balancer including the HTTP headers and SSL sessions and distributes the server load based on the decision arising from a combination of several variables.
-> This way application load balancers control the server traffic based on the individual usage and behavior, has context menu

c.) Global Server Load Balancer/Multi-site Load Balancer:
With the increasing number of applications being hosted in cloud data centers, located at varied geographies, the GSLB extends the capabilities of general L4 and L7 across various data centers facilitating the efficient global load distribution, without degrading the experience for end users. In addition to the efficient traffic balancing, multi-site load balancers also help in quick recovery and seamless business operations, in case of server disaster or disaster at any data center, as other data centers at any part of the world can be used for business continuity.

What is Application Load Balancing?
Load balancing is a common networking term that refers to distributing the workload across multiple servers and other network resources at the application layer of the OSI network model. Typically, this involves load balancing at web application protocol level (HTTP/HTTPS, FTP, SMTP, DNS, SSH, etc.), for network health checking, server monitoring, network traffic optimization, minification, and caching.

Types of Load Balancers – Based on Configurations
Load Balancers are also classified as:
a.) Hardware Load Balancers:

As the name suggests, this is a physical, on-premise, hardware equipment to distribute the traffic on various servers. Though they are capable of handling a huge volume of traffic but are limited in terms of flexibility, and are also fairly high in prices.
b.) Software Load Balancers:

They are the computer applications that need to be installed in the system and function similarly to the hardware load balancers. They are of two kinds- Commercial and Open Source and are a cost-effective alternative to the hardware counterparts.
c.) Virtual Load Balancers:

This load balancer is different from both the software and hardware load balancers as it is the combination of the program of a hardware load balancer working on a virtual machine.
 
https://www.appviewx.com/wp-content/uploads/2021/01/software-load-balancers.png

Through virtualization, this kind of load balancer imitates the software driven infrastructure. The program application of hardware equipment is executed on a virtual machine to get the traffic redirected accordingly. But such load balancers have similar challenges as of the physical on-premise balancers viz. lack of central management, lesser scalability and much limited automation.
 
-> Different types of lead balancers with different capabilities reside in the architecture called Open System interconnections model
		-> In this model there area seven layers .Network firewalls area ta levels onto to three (physical , data link , network )
		-> Meanwhile , load balancing happens at layers four to seven (transport, session, presentation , application)
		-> Load balancers are generally used at Layer 4 and Layer 7

-> Different types of lead balancers with different capabilities reside in the architecture called Open System interconnections model
		-> In this model there area seven layers .Network firewalls area ta levels onto to three (physical , data link , network )
		-> Meanwhile , load balancing happens at layers four to seven (transport, session, presentation , application)
		-> Load balancers are generally used at Layer 4 and Layer 7

Load balances help IT departments ensure scalability and availability of services. This advanced traffic management feature can help your business steer requests more efficiently to the right resources for each end user. In addition, ADC offers additional functions (like encryption, authentication, and web application firewalling) than other security tools.

All kinds of Load Balancers receive the balancing requests, which are processed in accordance with a pre-configured algorithm.
3.1: Industry Standard Algorithms
The most common load balancing methodologies include:
a) Round Robin Algorithm:
It relies on a rotation system to sort the traffic when working with servers of equal value. The request is transferred to the first available server and then that server is placed at the bottom of the line.
b) Weighted Round Robin Algorithm:
This algorithm is deployed to balance loads of different servers with different characteristics.
c) Least Connections Algorithm:
In this algorithm, traffic is directed to the server having the least traffic. This helps maintain the optimized performance, especially at peak hours by maintaining a uniform load at all the servers.
d) Least Response Time Algorithm:
This algorithm, like the least connection one, directs traffic to the server with a lower number of active connections and also considers the server having the least response time as its top priority.
e) IP Hash Algorithm:
A fairly simple balancing technique assigns the client’s IP address to a fixed server for optimal performance.
What are some of the common load-balancing algorithms?
Load balancing happens when the algorithm used by the load balancer determines how to distribute traffic across multiple servers, such as a server farm. Here are many ways, ranging from simple to complex.

Round-robin is a simple technique for guaranteeing that every user gets a different server. Load balancers are simple but don’t account for the loads already on the server. As a result, there is a danger that a server may become very busy and become overloaded. This might slow down the server, and this may cause problems for customers or clients.
 
https://www.appviewx.com/wp-content/uploads/2021/01/Round-Robin-load-balancing-algorithms.png
 
Least response time method

A more sophisticated version of the slightest connection method, the least response time method relies on the time taken by a server to respond to a health monitoring request. The response time indicates how loaded the server is and how well the users receive your site or service. Some load balancers can also consider the number of active connections on each server.
Least connection method

Whereas round-robin doesn’t account for the current load on a server, the least connection method does make this evaluation, and as a result, it often delivers better performance. A virtual server following the least connection method will look to send requests to the server with the least number of active connections.

https://www.appviewx.com/wp-content/uploads/2021/01/least-connection-method-load-balancing-algorithms.png

Least bandwidth method
A relatively simple algorithm, the least bandwidth method looks for the server currently serving the minor traffic as measured in megabits per second (Mbps). For example, in TCP, the least-recently-used method selects the server that has been connected to the least number of times over a given time.
Hashing methods
Methods in this category make decisions based on various data from the incoming packet. This includes connection or header information, such as source/destination IP address, port number, URL, or domain name.

Custom load method
The custom load method lets the load balancer query the load on individual servers via SNMP. An administrator can define which servers need to be queried and how to combine those server loads into a metric that reflects the user experience.
 
Other Specific Algorithm
a) Least Bandwidth Algorithm: In this method, the traffic is measured in Mbps, and the client request is sent to the server with the least Mbps of traffic.
b) Resource-Based (Adaptive) Algorithm: In this method, a computer program is installed in a server that reports the current load to the balancer. That agent program then assesses the servers and resource availability to direct the traffic at the best-suited server at the moment.
c) Resource-Based (SDN Adaptive) Algorithm: In this method, comprehensive knowledge from all layers of the application and inputs from an SDN Controller is analyzed to make better decisions regarding traffic distribution.
d) Source IP Hash: In this method, the client’s and server’s IP addresses are mixed to generate a unique hash key, which then allocates the traffic to a particular server.
e) URL Hash: This algorithm distributes writes uniformly across multiple sites direct all reads to the website owning a particular object.

Benefits to the website/application:
1. Enhanced Performance: Load Balancers reduce the additional load on a particular server and ensures seamless operations and response, giving the clients a better experience.
2. Resilience: The failed and under-performing components can be substituted immediately and giving information about which equipment needs service, with nil or negligible downtime.
3. Security: Without any change in any form, Load Balancer gives an additional layer of security to your website and applications.
 
Benefits to the organizations
1. Scalability: Without disrupting the services, Load Balancers make it easy to change the server infrastructure anytime.
2. Predictive Analysis: Software load balancers can predict traffic bottlenecks before they happen in reality.
3. Big Data: Actionable insights out of the big data generated by global users can be analyzed to drive better and informed business decisions.

devops- refers to development plus operations.
in devops we manage a project from end to end.
we build a project, write the source code, make commits to the source code to achieve the desired state, test these commits or changes and deploy the project.
in simple we handle the project lifecycle in its entirety.
there were conventional methods prior to devops which were slow and had some limitations.
by employing devops we can make the project lifecycle more agile and overcome those limitations.
the first step in devops is to prepare and host the source code for the project.
the hosting of this source code and the possible ways of doing it is what we call as version control systems(vcs).

version control system

vcs refers to the position where the source code is hosted. based on this we have 3 different types of vcs. 
1. local vcs
2. central vcs
3. distributed vcs